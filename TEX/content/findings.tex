% !TeX root = ../SDonchezResearchIReport.tex

\section{Findings}\label{sec:findings}
The implementation of the EDF algorithm and testbench on the Windows target has revealed that it is able to successfully schedule tasks at high utilization levels with low miss rates, given that the requirements outlined in the design constraints and assumptions are met. Careful analysis of the scheduler's output reveals that it is scheduling in accordance with the algorithm, with only a single exception - at the end of the simulation, as the task queue depletes, the scheduler unnecessarily shifts tasks from higher index cores to vacant lower-indexed cores. Ultimately, this inconsistency is non-consequential, as in a real-world implementation it is unlikely that the task queue would ever be depleted (and also as it does not cause any tasks to miss their deadline).

\subsection{Scheduler Effectiveness}\label{subsec:schedulerData}
As the primary measure of success for this scheduler implementation is how it performs under heavy load, a series of trials were conducted on the hardware target under varying levels of load in order to determine the average performance of the algorithm for each loading. These results are described in Table \ref{table:SchedEffectiveness}, below. All iterations were performed for a simulation of 1000 TimeUnits. The results below are computed from the average of three trials for each utilization, each utilizing a different randomly generated set of tasks.

\begin{table}[h!]
    \centering\begin{tabular}{| c | c | c | c |}
        \hline
        Target Utilization & Num. Tasks & Units Elapsed & \% Units Missed \\
        \hline
        50\% & 38 & 512 & 0\% \\
        60\% & 47 & 604 & 0\% \\
        70\% & 53 & 732 & 0\% \\
        80\% & 64 & 825 & 0\% \\
        90\% & 74 & 925 & 0.15\% \\
        100\% & 82 & 1000 & 8.63\% \\
        \hline
    \end{tabular}
    \caption{Scheduler Effectiveness}
    \label{table:SchedEffectiveness}
\end{table}

\subsection{Performance Evaluation}\label{subsec:performanceData}
Although the effectiveness of the algorithm (and its implementation) are by far the most important criteria for evaluating their success, it is also important to consider the performance of the application. In the context of the larger system outlined in Section \ref{sec:Proposal}, a number of other processes will likely have to execute on the single core available on the hardware target. Accordingly, it is crucial that the scheduler is not overtaxing the HPS, such that the other portions of the system are also able to execute as needed. Accordingly, Table \ref{table:SchedPerf}, below, reports on the total utilization time of the processor for each of the iterations above.

\begin{table}[h!]
    \centering\begin{tabular}{| c | c | c | c | c |}
        \hline
        Utilization & Clock Time & User Time & Sys Time & RAM Used \\
        \hline
        50\% & 10.79s & 10.34s & 0.07s & 10.48MB \\
        60\% & 11.04s & 10.35s & 0.06s & 10.63MB \\
        70\% & 10.85s & 10.35s & 0.07s & 10.61MB \\
        80\% & 10.93s & 10.33s & 0.11s & 10.54MB \\
        90\% & 10.87s & 10.39s & 0.05s & 10.73MB \\
        100\% & 10.92s & 10.39s & 0.09s & 10.63MB \\
        \hline
    \end{tabular}
    \caption{Scheduler Performance}
    \label{table:SchedPerf}
\end{table}

\subsection{Analysis of Findings}\label{subsec:findingsAnalysis}
These findings indicate a high level of success on the part of the scheduling algorithm, as it effectively schedules tasks even at high levels of utilization. It is worth noting that the case of 100\% utilization is a special case, as a detailed analysis of individual runs reveals some discrepencies that explain the high miss rate. The current implementation of the testbench does not immediately send a task at TimeUnit = 0 on every iteration, as its operation is, by design, random. As a result, the logged allocation of cores to tasks often indicates empty cores for the first several TimeUnits. However, the testbench is still attempting to generate 100\% of the TimeUnits (4000 in the case of these trials), meaning that it will occasionally overschedule the processor. It has been observed through additional experimentation that the increase in miss rate between 90\% and 100\% utilization more nearly approximates an exponenetial line of best fit than a linear one, further validating the performance of the algorithm.

It should also be noted that much of the "User Time" listed in Table \ref{table:SchedPerf} above is currently "idle" time. As the current implementation of the scheduler is not controlling real IP, most of the time in each TimeUnit is spent waiting for the unit to expire. This waiting process is not  optimized to minimize processor consumption in the implementation used to generate these results, as it is a placeholder for future work.

Additionally, resource consumption is not closely correlated with target utilization, but appears roughly constant across all target utilization levels. This is highly beneficial in this scenario, as, with the larger and more complex Task data that will necessarily accompany real tasks being implemented on real IP, any utilization correlated growth in resource consumption would be greatly magnified (and as it is desireable to maximize utilization for revenue purposes on the part of the service provider).